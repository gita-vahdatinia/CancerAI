{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training variants: 3321\n",
      "Number of test variants: 5668\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Read Data \"\"\"\n",
    "train_variant = pd.read_csv(\"../input/training_variants\")\n",
    "test_variant = pd.read_csv(\"../input/test_variants\")\n",
    "train_text = pd.read_csv(\"../input/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "test_text = pd.read_csv(\"../input/test_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "train = pd.merge(train_variant, train_text, how='left', on='ID')\n",
    "train_y = train['Class'].values\n",
    "train_x = train.drop('Class', axis=1)\n",
    "train_size=len(train_x)\n",
    "print('Number of training variants: %d' % (train_size))\n",
    "# number of train data : 3321\n",
    "\n",
    "test_x = pd.merge(test_variant, test_text, how='left', on='ID')\n",
    "test_size=len(test_x)\n",
    "print('Number of test variants: %d' % (test_size))\n",
    "# number of test data : 5668\n",
    "\n",
    "test_index = test_x['ID'].values\n",
    "test_x['ID'] = test_x.ID.astype(int)\n",
    "all_data = np.concatenate((train_x, test_x), axis=0)\n",
    "all_data = pd.DataFrame(all_data)\n",
    "all_data.columns = [\"ID\", \"Gene\", \"Variation\", \"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID    Gene             Variation  \\\n",
       "0  0  FAM58A  Truncating Mutations   \n",
       "1  1     CBL                 W802*   \n",
       "2  2     CBL                 Q249E   \n",
       "3  3     CBL                 N454D   \n",
       "4  4     CBL                 L399V   \n",
       "\n",
       "                                                Text  \n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
       "1   Abstract Background  Non-small cell lung canc...  \n",
       "2   Abstract Background  Non-small cell lung canc...  \n",
       "3  Recent evidence has demonstrated that acquired...  \n",
       "4  Oncogenic mutations in the monomeric Casitas B...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-54c3f01c4bc7>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-54c3f01c4bc7>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    allText = all_data['Text'].apply(cleanup)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from gensim.models.doc2vec import LabeledSentence\n",
    "# from gensim import utils\n",
    "\n",
    "# def constructLabeledSentences(data):\n",
    "#     sentences=[]\n",
    "#     for index, row in data.iteritems():\n",
    "#         sentences.append(LabeledSentence(utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)]))\n",
    "#     return sentences\n",
    "\n",
    "# def textClean(text):\n",
    "#     text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "#     text = text.lower().split()\n",
    "#     stops = set(stopwords.words(\"english\"))\n",
    "#     text = [w for w in text if not w in stops]    \n",
    "#     text = \" \".join(text)\n",
    "#     return(text)\n",
    "    \n",
    "# def cleanup(text):\n",
    "#     text = textClean(text)\n",
    "#     text= text.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "#     return text\n",
    "\n",
    "# print(cleanup(all_data['Text'])\n",
    "# allText = all_data['Text'].apply(cleanup)\n",
    "# sentences = constructLabeledSentences(allText)\n",
    "# allText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0e14eabd2869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#     return text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mallText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from gensim.models.doc2vec import LabeledSentence\n",
    "# from gensim import utils\n",
    "\n",
    "# def constructLabeledSentences(data):\n",
    "#     sentences=[]\n",
    "#     for index, row in data.iteritems():\n",
    "#         sentences.append(LabeledSentence(utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)]))\n",
    "#     return sentences\n",
    "\n",
    "# def textClean(text):\n",
    "#     text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "#     text = text.lower().split()\n",
    "#     stops = set(stopwords.words(\"english\"))\n",
    "#     text = [w for w in text if not w in stops]    \n",
    "#     text = \" \".join(text)\n",
    "#     return(text)\n",
    "    \n",
    "def cleanup(text):\n",
    "    text = text.lower()\n",
    "    text= text.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    return text\n",
    "\n",
    "#     text = textClean(text)\n",
    "#     text= text.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "#     return text\n",
    "\n",
    "train_data['Text'] = train_data['Text'].apply(cleanup)\n",
    "test_data['Text'] = test_data['Text'].apply(cleanup)\n",
    "allText = train_data['Text'].append(test_data['Text'], ignore_index=True)\n",
    "\n",
    "print (allText)\n",
    "# print(cleanup(all_data['Text'])\n",
    "# allText = all_data['Text'].apply(cleanup)\n",
    "# sentences = constructLabeledSentences(allText)\n",
    "# allText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
